{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social bubbles with Covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the simulator on the network with bubbles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import simulation_functions_new as DCT\n",
    "from utils import temporal_graph_load\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_I_list = [0.1,0.25,0.4]\n",
    "eps_T_list = [0,0.01,0.1,0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = 'synth' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "nb_ideas = 20\n",
    "k_threshold = np.full(nb_ideas,K)\n",
    "#k_threshold = [10, 8, 12, 12, 8, 8, 10, 12, 10, 12, 8, 12, 12, 10, 8, 8, 10, 12, 10, 8] #mix1\n",
    "#k_threshold = [10, 8, 12] #mix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {'temporal_gap' : 3600*2,              # Temporal gap between static networks (sec)\n",
    "              'nb_nodes' : 850,\n",
    "              'nb_clusters' : 10,                   # Nb of clusters in networks\n",
    "              'cluster_size' : 85,                  # Cluster size\n",
    "              'nb_ideas' : len(k_threshold),                # Nb of ideas\n",
    "              'nb_links' : 625,                     # nb of links in networks\n",
    "              'memory_contacts' : 7,                # Tracing memory (days)\n",
    "              'max_time_quar' : 10,                 # Quarantine duration (days)\n",
    "              'max_time_iso' : 25,                  # Isolation duration (days)\n",
    "              'eps_Is' : eps_I_list,                # Isolation effectivity\n",
    "              'eps_Ts' : eps_T_list,                # Tracing effectivity\n",
    "              'recov_time' : 25,                    # recovery time\n",
    "              'k_threshold' : k_threshold,          # Knowledge spreading parameter\n",
    "              'times' : 200,                      # Number of repetition of the simulation\n",
    "              'seed' : 11,                          # Random seed \n",
    "              'symptomatics' : 0.8,                 # Fraction of symptomatic individuals \n",
    "              'testing' : 0.0,                      # Fraction of asymptomatics who are detected via random testing\n",
    "              'net' : net,\n",
    "              'store':{'to_store': True,            # Save the results?\n",
    "                       'path_to_store':'RESULTS/'}} # Target folder to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and graph length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = PARAMETERS['nb_clusters']\n",
    "nb_nodes = PARAMETERS['nb_nodes']\n",
    "cluster_size = nb_nodes/nb_clusters\n",
    "if PARAMETERS['cluster_size'] != cluster_size:\n",
    "    print('ERRORE!!!')\n",
    "L = PARAMETERS['nb_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_store_path(path_to_store,eps_I,eps_T):\n",
    "    if all(el == PARAMETERS['k_threshold'][0] for el in PARAMETERS['k_threshold']): # True if all K are the same\n",
    "        name='/epsI_' + str(eps_I)+'_epsT_'+str(eps_T) + '_kThresh_'+str(PARAMETERS['k_threshold'][0])+'/'\n",
    "    else:\n",
    "         name='/epsI_' + str(eps_I)+'_epsT_'+str(eps_T) + '_kThresh_mix2/'\n",
    "    #print(path_to_store)\n",
    "    #print(name)\n",
    "    path_to_store += name\n",
    "\n",
    "    if not os.path.exists(path_to_store):\n",
    "        os.makedirs(path_to_store)\n",
    "    return path_to_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulations and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random seed\n",
    "np.random.seed(PARAMETERS['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = True\n",
    "round_days = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_intra 0.01203\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Graphs/850nodes/10clusters_85nodes/temporal_net_p_intra1.20E-02_p_inter6.01E-04_rounds10days/num_snapshots.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5bf85b8dd00a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgraph_name\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'_rounds%ddays'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mround_days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemporal_graph_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpath_to_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARAMETERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'store'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path_to_store'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Progetti_post_doc/bolle_sociali/code/server code/utils.py\u001b[0m in \u001b[0;36mtemporal_graph_load\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Graphs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'num_snapshots.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mn_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Graphs/850nodes/10clusters_85nodes/temporal_net_p_intra1.20E-02_p_inter6.01E-04_rounds10days/num_snapshots.txt'"
     ]
    }
   ],
   "source": [
    "#for p_intra in [0.00483,0.00621,0.00725,0.00781,0.00806,0.00838,0.00849,0.00854,0.00858,0.0086,0.00863,0.00865]: #5 clusters\n",
    "#for p_intra in [0.00621,0.0121,0.01485,0.01393,0.01609,0.01655,0.01679,0.01694,0.01704,0.01717,0.01727]: #10 clusters\n",
    "#for p_intra in [0.00725,0.02562,0.02981,0.03154,0.03247,0.03306,0.03347,0.03399,0.03443]: #20 clusters\n",
    "\n",
    "\n",
    "#for p_intra in [0.00621,0.01203,0.01481,0.01605,0.01650,0.01674]: \n",
    "for p_intra in [0.01203]: \n",
    "    print('p_intra',p_intra)\n",
    "    p_inter = 2*L/(nb_clusters*(nb_clusters-1)*cluster_size**2) - (cluster_size-1)*p_intra/((nb_clusters-1)*cluster_size)\n",
    "    graph_name = '%dnodes/%dclusters_%dnodes/temporal_net_p_intra%.2E_p_inter%.2E'%(nb_nodes,nb_clusters,cluster_size,p_intra,p_inter)\n",
    "    if rounds:\n",
    "        graph_name += '_rounds%ddays'%round_days\n",
    "        \n",
    "    graphs = temporal_graph_load(graph_name)\n",
    "    path_to_store = PARAMETERS['store']['path_to_store'] + graph_name\n",
    "    \n",
    "    #for eps_I in eps_I_list:\n",
    "    for eps_I in [0.25]:\n",
    "        for eps_T in eps_T_list[:1]:\n",
    "        \n",
    "            print('eps_I',eps_I,'eps_T',eps_T)\n",
    "            \n",
    "            path_to_store_upd = update_store_path(path_to_store,eps_I,eps_T)\n",
    "            \n",
    "            print(path_to_store_upd)\n",
    "\n",
    "            # Print some report\n",
    "            print('-' * 100)\n",
    "            print('Running simulation with')\n",
    "            print('       |_ eps_T             : %4.2f'   % eps_T)\n",
    "            print('       |_ eps_I             : %.3f'   % eps_I)\n",
    "            print('       |_ p_intra             : %.5f'   % p_intra)\n",
    "            print('')\n",
    "\n",
    "\n",
    "            # Repeat the simulation for a fixed configuration             \n",
    "            for i in tqdm(range(PARAMETERS['times'])):\n",
    "                \n",
    "                # Initialize the simulation object\n",
    "                dct = DCT.DigitalContactTracing(path_to_store_upd,\n",
    "                                                graphs=graphs,\n",
    "                                                PARAMETERS = PARAMETERS,\n",
    "                                                eps_I=eps_I,\n",
    "                                                eps_T=eps_T,\n",
    "                                                realization=i)\n",
    "                # Run the actual simulation\n",
    "                res = dct.simulate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results after the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nodes = nb_clusters*cluster_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_intra = 0.00483 #5 clusters\n",
    "p_inter = 2*L/(nb_clusters*(nb_clusters-1)*cluster_size**2) - (cluster_size-1)*p_intra/((nb_clusters-1)*cluster_size)\n",
    "graph_name = '%dclusters_%dnodes/temporal_net_p_intra%.2E_p_inter%.2E'%(nb_clusters,cluster_size,p_intra,p_inter)\n",
    "if rounds:\n",
    "    graph_name += '_rounds%ddays'%round_days\n",
    "path = PARAMETERS['store']['path_to_store'] + graph_name\n",
    "print(path)\n",
    "eps_I = eps_I_list[0]\n",
    "eps_T = eps_T_list[0]\n",
    "path = update_store_path(path,eps_I,eps_T)\n",
    "print(path)\n",
    "\n",
    "for real in range(PARAMETERS['times']): # for each realization\n",
    "    # load act_inf:\n",
    "    globals()['r%d_act_inf'%real] = np.load(path + '%d_act_inf.npy'%real)\n",
    "    # load isolated:\n",
    "    globals()['r%d_isolated'%real] = np.load(path + '%d_isolated.npy'%real)\n",
    "    # load recovered:\n",
    "    globals()['r%d_recovered'%real] = np.load(path + '%d_recovered.npy'%real)\n",
    "    if eps_T > 0:\n",
    "        # load quarantined:\n",
    "        globals()['r%d_quarantined'%real] = np.load(path + '%d_quarantined.npy'%real)\n",
    "\n",
    "    # load ideas_per_node and nodes_per_idea at all times:\n",
    "    globals()['r%d_ideas_per_node'%real] = np.load(path + '%d_ideas_per_node.npy'%real)\n",
    "    globals()['r%d_nodes_per_idea'%real] = np.load(path + '%d_nodes_per_idea.npy'%real)\n",
    "    \n",
    "    # ideas acquired at time t:\n",
    "    #for t in range(len(graphs)):\n",
    "    for t in range(11):\n",
    "        globals()['r%d_ideas_per_node_time_%d'%(real,t)] = r0_ideas_per_node[t*nb_nodes:(t+1)*nb_nodes] # time t\n",
    "        globals()['r%d_nodes_per_idea_time_%d'%(real,t)] = r0_nodes_per_idea[t*nb_ideas:(t+1)*nb_ideas] # time t\n",
    "\n",
    "        # load effective edgelist:\n",
    "        globals()['r%d_eff_edgelist_time_%d'%(real,t)] = np.load(path + 'eff_edgelist/%d_eff_edgelist_time_%d.npy'%(real,t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = 1\n",
    "t = 10\n",
    "globals()['r%d_eff_edgelist_time_%d'%(real,t)] = np.load(path + 'eff_edgelist/%d_eff_edgelist_time_%d.npy'%(real,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_eff_edgelist_time_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_ideas_per_node_time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_nodes_per_idea_time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_eff_edgelist_time_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nodes = 10\n",
    "nb_ideas = 3\n",
    "know_old = np.full((nb_nodes, nb_ideas), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "know_old[0][2] = 1\n",
    "\n",
    "know_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nodes_per_idea = np.sum(know_old,axis=0)\n",
    "nb_nodes_per_idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ideas_per_node = np.sum(know_old,axis=1)\n",
    "nb_ideas_per_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [0,1,0,1]\n",
    "v.index(1,0,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
